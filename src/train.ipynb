{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "apart-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Dataset\n",
    "\n",
    "from Load import load_shot, load_eig, load_dist\n",
    "from FAUSTDataset import FAUSTDataset\n",
    "from ResNet import DFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unique-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "train_reg_shot = 'training/reg_shot/'\n",
    "train_scan_shot = 'training/scan_shot/'\n",
    "train_eigen = 'training/reg_lb/'\n",
    "train_dist = 'training/l2_dist/'\n",
    "test_scan_shot = 'test/scan_shot/'\n",
    "test_eigen = 'test/scan_lb/'\n",
    "inter = 'inter_challenge.txt'\n",
    "intra = 'intra_challenge.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aerial-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=True\n",
    "batch_size=32\n",
    "lr = 0.001\n",
    "max_epoch=50\n",
    "eignum = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "regulation-promise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded all\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 4 required positional arguments: 'src_shot', 'tar_shot', 'src_eigen', and 'tar_eigen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-3791de346eef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# import model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDFM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 4 required positional arguments: 'src_shot', 'tar_shot', 'src_eigen', and 'tar_eigen'"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "shot = []\n",
    "eigen = []\n",
    "dist = []\n",
    "if train:\n",
    "    streig = \"%d\" % (eignum)\n",
    "    for i in range(100):\n",
    "        strnum = '%03d' % (i)\n",
    "#                 data_dir, train_reg_shot, \n",
    "        fn = ''.join([data_dir, train_reg_shot, 'tr_reg_res_', strnum, '.txt'])\n",
    "        shot.append(load_shot(fn))\n",
    "        fn_eig = ''.join([data_dir, train_eigen, 'tr_reg_', streig, '_', strnum, '.h5'])\n",
    "        eigen.append(load_eig(fn_eig))\n",
    "#         fn_dist = ''.join([data_dir, train_dist, 'tr_reg_dist_', strnum, '.h5'])\n",
    "#         dist.append(load_dist(fn_dist))\n",
    "print('loaded all')\n",
    "    \n",
    "train_dataset = FAUSTDataset(train, shot, eigen, dist)\n",
    "\n",
    "train_loader = Dataset.DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=1, drop_last=False\n",
    "                         )\n",
    "\n",
    "# import model\n",
    "model = DFM(train)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999), eps=1e-08)\n",
    "\n",
    "# loss\n",
    "criterion = EuclideanLoss()\n",
    "\n",
    "for epoch in range(0, max_epoch):\n",
    "    if epoch % 100 > 0:\n",
    "        epoch *= 0.1\n",
    "        \n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for data in enumerate(train_loader):\n",
    "        src_shot, tar_shot, src_eigen, tar_eigen = data\n",
    "        optimizer.zero_grad()\n",
    "        # P: soft corr matrix\n",
    "        P, C = model(src_shot, tar_shot, src_eigen, tar_eigen)\n",
    "        loss = criterion(P, src_dist, tar_dist)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"[{0}/{1}] Loss: {2}\".format(epoch, max_epoch, total_loss/batch_size))\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join('{}.pth'.format(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-purse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

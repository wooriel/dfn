{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data.Dataset as Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "train_scan_shot = 'training/scan_shot'\n",
    "train_eigen = 'training/scan_lb/'\n",
    "test_scan_shot = 'test/scan_shot/'\n",
    "test_eigen = 'test/scan_lb/'\n",
    "inter = 'inter_challenge.txt'\n",
    "intra = 'intra_challenge.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAUSTDataset(Dataset):\n",
    "    def __init__(self, train, eignum=120):\n",
    "        self.train = train\n",
    "        self.shot_des = []\n",
    "        self.eigen_des = []\n",
    "        self.eignum = eignum\n",
    "        \n",
    "        if self.train:\n",
    "            streig = \"%d\" % (eignum)\n",
    "            for i in range(100):\n",
    "                strnum = '%03d' % (i)\n",
    "                fn = ''.join([data_dir, train_scan_shot, 'tr_scan_d_res_', strnum, '.txt'])\n",
    "                self.shot_des.append(self.load_shot(fn))\n",
    "                fn_eig = ''.join([data_dir, train_eigen, 'tr_scan_', streig, '_', strnum, '.h5'])\n",
    "                self.eigen_des.append(self.load_eig(fn_eig))\n",
    "        else:\n",
    "            pairs = self.load_pairs()\n",
    "            for i in range(100):  \n",
    "                fn1 = ''.join([data_dir, test_scan_shot, 'test_scan_d_res_', pairs[i][0], '.txt'])\n",
    "                fn2 = ''.join([data_dir, test_scan_shot, 'test_scan_d_res_', pairs[i][1], '.txt'])\n",
    "                self.shot_des.append(self.load_shot(fn1))\n",
    "                self.shot_des.append(self.load_shot(fn2))\n",
    "                fn_eig1 = ''.join([data_dir, test_eigen, 'test_scan_', streig, '_', pairs[i][0], '.h5'])\n",
    "                fn_eig2 = ''.join([data_dir, test_eigen, 'test_scan_', streig, '_', pairs[i][1], '.h5'])\n",
    "                self.eigen_des.append(self.load_eig(fn_eig1))\n",
    "                self.eigen_des.append(self.load_eig(fn_eig2))\n",
    "            \n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.shot_des)\n",
    "        else:\n",
    "            return len(self.shot_dex)//2\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            s = self.shot_des[idx]\n",
    "            e = self.eigen_des[idx]\n",
    "            return s, e\n",
    "        else:\n",
    "            src_idx = idx*2-1\n",
    "            tar_idx = idx*2\n",
    "            s_src = self.shot_des[src_idx]\n",
    "            s_tar = self.shot_des[tar_idx]\n",
    "            e_src = self.eigen_des[src_idx]\n",
    "            e_tar = self.eigen_des[tar_idx]\n",
    "            return s_src, s_tar, e_src, e_tar\n",
    "        \n",
    "    def load_pairs(self):\n",
    "        intraFname = ''.join([data_dir, intra])\n",
    "        interFname = ''.join([data_dir, inter])\n",
    "        pairs = []\n",
    "        with open(intraFname) as f:\n",
    "            for line in f:\n",
    "                array = line.split('_')\n",
    "                array[1] = array[1][:-1]\n",
    "                pairs.append(array)\n",
    "        with open(intraFname) as f:\n",
    "            for line in f:\n",
    "                array = line.split('_')\n",
    "                pairs.append(array)\n",
    "        return pairs\n",
    "        \n",
    "    def load_shot(self, fname):\n",
    "        i = 0\n",
    "        shot = []\n",
    "        \n",
    "        with open() as fname:\n",
    "            for line in fname:\n",
    "                array = line.split()\n",
    "                if len(array) > 0:\n",
    "                    np_array = np.array(array)\n",
    "                    f_array = np_array.astype(float)\n",
    "                    t_array = torch.from_numpy(f_array)\n",
    "                    shot.append(f_array)\n",
    "                i = i + 1\n",
    "        shot_np = np.array(shot)\n",
    "        shot_np = shot_np[shot_np[:,0].argsort()]\n",
    "        shot_ret = shot_np[:, 4:]\n",
    "        shot_ret = shot_np\n",
    "        t_shot = torch.from_numpy(shot_ret) #shot_ret\n",
    "#         t_shot = torch.unsqueeze(t_shot, 0).float().to(cuda_device)\n",
    "        f.close()\n",
    "        return t_shot\n",
    "    \n",
    "    def load_eig(self, fname):\n",
    "        file = h5py.File(fname)\n",
    "        dkey = list(file.keys())[0]\n",
    "        dset = file[dkey]\n",
    "        nData = np.array(dset)\n",
    "        nData = np.transpose(nData)\n",
    "        numVert = int(nData[0][0])\n",
    "        numEig = int(nData[0][1])\n",
    "        phi = nData[1]\n",
    "        \n",
    "        vertice = nData[2:numVert+2]\n",
    "        nd_vert = np.array(vertice)\n",
    "        nd_vert = nd_vert.astype(float)\n",
    "        t_vert = torch.from_numpy(nd_vert)\n",
    "        \n",
    "        return t_vert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

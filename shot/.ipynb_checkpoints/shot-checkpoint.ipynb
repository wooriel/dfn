{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "separate-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import argparse\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from plyfile import PlyData, PlyElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "seven-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse arguments\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--data_dir', type=str, default='/data')\n",
    "# args = parser.parse_args()\n",
    "data_dir = '../data/'\n",
    "data_type = 'training/reg_shot/'\n",
    "data_type2 = 'test/scan_shot/'\n",
    "inter = 'inter_challenge.txt'\n",
    "intra = 'intra_challenge.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessory-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pairs(challenge):\n",
    "    # this load pairs of string number ['000', '003']\n",
    "    # challenges can be intra / inter challenge / both\n",
    "    \n",
    "    intraFname = ''.join([data_dir, intra])\n",
    "    interFname = ''.join([data_dir, inter])\n",
    "    pairs = []\n",
    "    if challenge == 'intra' or challenge == 'both':\n",
    "        with open(intraFname) as f:\n",
    "            for line in f:\n",
    "                array = line.split('_')\n",
    "                array[1] = array[1][:-1]\n",
    "                pairs.append(array)\n",
    "    elif challenge == 'inter' or challenge == 'both':\n",
    "        with open(intraFname) as f:\n",
    "            for line in f:\n",
    "                array = line.split('_')\n",
    "                pairs.append(array)\n",
    "    else:\n",
    "        print('error: please select right challenge')\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automated-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reg(p):\n",
    "#     # types can be registration / all(scanned)\n",
    "#     p[:] = [elem for elem in p if int(elem[0]) < 100 and int(elem[1]) < 100]\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "asian-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shot(fname):\n",
    "    # f = open(fname, 'r')\n",
    "    # all_cont = f.read()\n",
    "    num = 0\n",
    "    i = 0\n",
    "    shot = []\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "            array = line.split()\n",
    "#             print(len(array))\n",
    "            num += len(array)\n",
    "            if len(array) > 0:\n",
    "                np_array = np.array(array)\n",
    "                f_array = np_array.astype(float)\n",
    "                shot.append(f_array)\n",
    "#                 print(len(array))\n",
    "#                 print(\"{0} - first: {1}\".format(i, array[0]))\n",
    "#                 print(\"{0} - second: {1}\".format(i, array[1]))\n",
    "#                 print(\"{0} - third: {1}\".format(i, array[2]))\n",
    "#                 print(\"{0} - forth: {1}\".format(i, array[3]))\n",
    "                \n",
    "#                 print(\"{0} - last: {1}\".format(i, array[355]))\n",
    "#             else:\n",
    "#                 print(\"end of file\")\n",
    "            i = i + 1\n",
    "#     print(\"shot shape {0}, {1}\".format(len(shot), len(shot[0])))\n",
    "    shot_np = np.array(shot)\n",
    "    shot_np = shot_np[shot_np[:,0].argsort()]\n",
    "    shot_ret = shot_np[:, 4:]\n",
    "#     print(\"shot shape {0}\".format(shot_np.shape))\n",
    "    print(shot_ret.shape)\n",
    "#     print(num)\n",
    "    f.close()\n",
    "#     shot = np.identity(6890)\n",
    "    # just returns array with (1000, array[i][0] number of descriptor length...?)\n",
    "    return shot_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "standard-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2(des, des2):\n",
    "    # make 1000*1000 distance matrix\n",
    "    l2_dist = []\n",
    "    print(\"des: {}\".format(des.shape))\n",
    "    print(\"des2 {}\".format(des2.shape))\n",
    "    for i in range(0,len(des)):\n",
    "        row = []\n",
    "        for j in range(0,len(des2)):\n",
    "#             sub = des[i] - des[j]\n",
    "# #             print(sub.shape)\n",
    "#             sq_sub = np.square(sub)\n",
    "# #             print(sq_sub.shape)\n",
    "#             sum_sq_sub = np.sum(sq_sub)\n",
    "# #             print(sum_sq_sub)\n",
    "#             l2_norm = np.sqrt(sum_sq_sub)\n",
    "#             print(l2_norm.shape)\n",
    "            l2_norm = np.sqrt(np.sum(np.square(des[i][0:]-des2[j][0:])))\n",
    "            row.append(l2_norm)\n",
    "        np_row = np.array(row)\n",
    "#         print(np_row.shape)\n",
    "        l2_dist.append(np_row)\n",
    "    np_dist = np.array(l2_dist)\n",
    "    print(np_dist.shape)\n",
    "    return np_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interpreted-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2_pt(des_i, des2):\n",
    "    lst = []\n",
    "    for k in range(0, des2.shape[0]):\n",
    "        l2_norm = np.sqrt(np.sum(np.square(des_i-des2[k][0:])))\n",
    "        lst.append(l2_norm)\n",
    "    np_lst = np.array(lst)\n",
    "    return np_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accessory-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_hitrate(matrix, k):\n",
    "    # first find k nearest neighbor in index\n",
    "    total_hit = 0 # total_hit = 1000\n",
    "    size = matrix.shape[0]\n",
    "    for i in range(size):\n",
    "        # sorts index from smallest to kth smallest\n",
    "        \n",
    "        if k < size:\n",
    "            knn = np.argpartition(matrix[i], k)[:k]\n",
    "#             print(knn)\n",
    "#             smallest = []\n",
    "#             for j in range(len(knn)):\n",
    "#                 smallest.append(matrix[i][knn[j]])\n",
    "#             smallest2 = sorted(matrix[i])[:k]\n",
    "#             smallest.sort()\n",
    "#             print(\"smallest {}\".format(smallest))\n",
    "#             print(\"smallest2 {}\".format(smallest2))\n",
    "        # same index presents -> hit\n",
    "#             print(\"i: {0}, knn: {1}\".format(i, knn))\n",
    "            if i in knn:\n",
    "                total_hit += 1\n",
    "        elif k == size:\n",
    "            total_hit += 1\n",
    "    return total_hit / size\n",
    "    \n",
    "    # information about argpartition\n",
    "    # https://numpy.org/doc/stable/reference/generated/numpy.argpartition.html\n",
    "    # https://stackoverflow.com/questions/34226400/find-the-index-of-the-k-smallest-values-of-a-numpy-array\n",
    "    # if the same index(row = i) presents, then it is hit -> later will be divided by 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instrumental-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scanned_hitrate_avg():\n",
    "    # make for lb operator later\n",
    "    # pair array\n",
    "    c = 'both'; # inter / intra / both\n",
    "    t = 'scan'; # reg (registration) / scan\n",
    "    pairs = load_pairs(c) # only load when t is 'scan'\n",
    "    \n",
    "    # number of nearest neighbors up to k\n",
    "    k = 100\n",
    "        \n",
    "    # load two pairs of shot descripted object\n",
    "    total_hit_rate = np.zeros(100)\n",
    "    for i in range(100):\n",
    "        fn1 = ''.join([data_dir, data_type2, 'test_scan_d_res_', pairs[i][0], '.txt'])\n",
    "        fn2 = ''.join([data_dir, data_type2, 'test_scan_d_res_', pairs[i][1], '.txt'])\n",
    "        shot1 = load_shot(fn1)\n",
    "        shot2 = load_shot(fn2)\n",
    "        \n",
    "        # get a distance map between two shots\n",
    "        d_map = compute_l2(shot1, shot2)\n",
    "        hit_rate = [] # this is single hit_rate map\n",
    "        for j in range(k):\n",
    "            hit_rate.append(find_hitrate(d_map, j))\n",
    "        np_hit = np.array(hit_rate)\n",
    "        print(np_hit.shape)\n",
    "        # add previous hit_rate map with new hit_rate map\n",
    "        total_hit_rate = np.add(total_hit_rate, np_hit)\n",
    "    \n",
    "    total_hit_rate = np.true_divide(total_hit_rate, 100)\n",
    "    return total_hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demanding-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale up by 100\n",
    "# def scale_up(factor, vertArr):\n",
    "#     scaleMatrix = np.identity(4)*100\n",
    "#     scaleMatrix[3, 3] = 1\n",
    "# #     print(scaleMatrix)\n",
    "#     res = []\n",
    "#     for i in range(vertArr.shape[0]):\n",
    "#         v4 = vertArr[i]\n",
    "#         v4 = np.append(v4, [1])\n",
    "#         resCoord = np.matmul(v4, scaleMatrix)\n",
    "#         res.append(resCoord[:3])\n",
    "#         # convert back into nparray\n",
    "#     to_ret = np.asarray(res)\n",
    "#     print(to_ret)\n",
    "#     return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "arranged-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dist_matrix(p1, p2):\n",
    "#     # p1, p2 are 3*1 ndarray\n",
    "#     v4 = np.subtract(p1, p2)\n",
    "#     v4 = np.append(v4, [1])\n",
    "#     M = np.matmul(v4, np.transpose(v4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "second-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py file (lb)\n",
    "def read_lap(i):\n",
    "    try:\n",
    "#         data_dir = '../data/'\n",
    "        training = True\n",
    "        scan = False\n",
    "        k = 120\n",
    "        \n",
    "        data_dir2 = 'training/' if training else 'test/'\n",
    "        data_dir3 = 'scan_lb/' if scan else 'reg_lb/'\n",
    "        prefix = 'tr_' if training else 'test_'\n",
    "        mid = 'reg_' if (training and not scan) else 'scan_'\n",
    "        strk = str(k)\n",
    "        num = '%03d' % i\n",
    "        \n",
    "        filename = \"\".join([data_dir, data_dir2, data_dir3, prefix, mid, strk, \"_\", num, \".h5\"])\n",
    "#         print(filename)\n",
    "        \n",
    "        file = h5py.File(filename)\n",
    "        dkey = list(file.keys())[0]\n",
    "        dset = file[dkey]\n",
    "        nData = np.array(dset)\n",
    "        nData = np.transpose(nData)\n",
    "#         print(nData.shape)\n",
    "        \n",
    "        numVert = int(nData[0][0])\n",
    "#         print(numVert)\n",
    "        numEig = int(nData[0][1])\n",
    "#         print(numEig)\n",
    "        phi = nData[1]\n",
    "#         print(phi)\n",
    "        \n",
    "        vertice = nData[2:numVert+2]\n",
    "        nd_vert = np.array(vertice)\n",
    "        nd_vert = nd_vert.astype(float)\n",
    "        print(vertice.shape)\n",
    "        \n",
    "#         file = h5py.File('../data/tr_scan_010.h5', 'r')\n",
    "# #         file = h5py.File(args.data_dir, 'r')\n",
    "#         # assume there's only one data key\n",
    "#         dkey = list(file.keys())[0]\n",
    "#         print(dkey)\n",
    "#         dset = file[dkey]\n",
    "#         print(\"{0}, {1}\".format(dset.dtype, dset.shape))\n",
    "#         nData = np.array(dset)\n",
    "#         nData = np.transpose(nData)\n",
    "#         print(nData.shape)\n",
    "#         numVert = int(nData[0][0])\n",
    "#         numFace = int(nData[0][1])\n",
    "#         vert = nData[1:numVert+1]\n",
    "#         print(\"numVert:{0}, vert shape:{1}\".format(numVert, vert.shape))\n",
    "#         face = nData[numVert+1:numVert+numFace+1]\n",
    "#         print(\"numFace:{0}, face shape:{1}\".format(numFace, face.shape))\n",
    "    except FileNotFoundError:\n",
    "        print('Cannot find the h5py binary file.');\n",
    "#     return vert, face\n",
    "    return vertice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "flying-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_func_map(matrix):\n",
    "#     pmatrix = matrix[0:100]\n",
    "#     pmatrix = pmatrix[:, 0:100]\n",
    "#     print(pmatrix)\n",
    "    plt.pcolor(matrix, cmap='RdBu')\n",
    "    plt.axis([0, matrix.shape[0]-1, 0, matrix.shape[1]-1])\n",
    "#     norm = ply.colors.Normalize(vmin=-1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expressed-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_3d_shape(x, y, z, row):\n",
    "    # please avoid using vis_3d_shape and vis_func_map together\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    \n",
    "    ax.scatter3D(x, y, z, c=row)\n",
    "#     plt.close('all')\n",
    "#     plt.colorbar()\n",
    "#         ax.plot_surface(xdata, ydata, zdata, cmap=row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "related-editing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6890, 120)\n",
      "(6890, 120)\n",
      "torch.Size([6890, 120])\n",
      "(6890, 120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-447d96a5a12d>:19: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  file = h5py.File(filename)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":   \n",
    "#     hit_rate_t = np.zeros(1000)\n",
    "#     for i in range(len(pairs)):\n",
    "#         # load two elements\n",
    "#         filename = ''.join([data_dir, data_type, 'tr_reg_res_', pairs[i][0], '.txt'])\n",
    "#         filename2 = ''.join([data_dir, data_type, 'tr_reg_res_', pairs[i][1], '.txt'])\n",
    "#         p1 = load_shot(filename)\n",
    "#         p2 = load_shot(filename2)\n",
    "#         n1 = np.array(p1)\n",
    "#         n2 = np.array(p2)\n",
    "#         n1 = n1.astype(float)\n",
    "#         n2 = n2.astype(float)\n",
    "#         dist_mat = compute_l2(n1, n2)\n",
    "# #         print(dist_mat.shape)\n",
    "        \n",
    "#         hit_rate = []\n",
    "#         for j in range(0, dist_mat.shape[0]):\n",
    "#             hit_rate.append(find_hitrate(dist_mat, j))\n",
    "#         np_hit = np.array(hit_rate)\n",
    "#         hit_rate_t = hit_rate_t + np_hit\n",
    "#     hit_rate_t = hit_rate_t * (1/dist_mat.shape[0])\n",
    "    \n",
    "#     plt.plot(hit_rate_t)\n",
    "#     plt.show()\n",
    "#     print(hit_rate_t)\n",
    "    \n",
    "    action1 = read_lap(0)\n",
    "    print(action1.shape)\n",
    "    action_t1 = torch.from_numpy(action1)\n",
    "    print(action_t1.size())\n",
    "    \n",
    "    action2 = read_lap(3)\n",
    "    actstrn1 = '%03d' % 0\n",
    "    actstrn2 = '%03d' % 3\n",
    "    \n",
    "    ##\n",
    "    # reading tr_reg_001.ply\n",
    "#     fnply1 = ''.join([data_dir, 'training/reg_100/', 'tr_reg_', actstrn2, '.ply'])\n",
    "#     pd = PlyData.read(fnply1)\n",
    "# #     print(plydata)\n",
    "#     print(pd.elements)\n",
    "#     x_coord = pd['vertex'].data['x']\n",
    "#     y_coord = pd['vertex'].data['y']\n",
    "#     z_coord = pd['vertex'].data['z']\n",
    "    \n",
    "    \n",
    "#     actfn1 = ''.join([data_dir, data_type, 'tr_reg_res_', actstrn1, '.txt'])\n",
    "#     actfn2 = ''.join([data_dir, data_type, 'tr_reg_res_', actstrn2, '.txt'])\n",
    "#     actshot1 = load_shot(actfn1)\n",
    "#     actshot2 = load_shot(actfn2)\n",
    "    \n",
    "#     shot_cmd = find_scanned_hitrate_avg()\n",
    "#     plt.plot(shot_cmd)\n",
    "#     plt.show()\n",
    "    \n",
    "    ## to view point distance from one point in other shape\n",
    "#     dist_point = compute_l2_pt(actshot1[0], actshot2)\n",
    "#     vis_3d_shape(x_coord, y_coord, z_coord, dist_point)\n",
    "    \n",
    "    ## to view functional map\n",
    "#     # action1, action2\n",
    "#     ident = np.identity(6890)\n",
    "#     proj1 = np.dot(np.transpose(actshot1), action1)\n",
    "#     print(proj1.shape)\n",
    "#     proj2 = np.dot(np.transpose(actshot2), action2)\n",
    "    \n",
    "\n",
    "#     res = np.linalg.lstsq(proj1, proj2, rcond=1)\n",
    "#     ct = res[0]\n",
    "#     c = np.transpose(ct)\n",
    "#     vis_func_map(c)\n",
    "    \n",
    "#     # scale by 100 should be done before shot/lb calculation\n",
    "#     dist_matrix = compute_l2(actshot1[0:100], actshot2[0:100])\n",
    "# #     print(dist_matrix)\n",
    "#     # right now, getting the hit rate for one object, but will average them later\n",
    "    \n",
    "#     hr = find_hitrate(dist_matrix, 3)\n",
    "#     print(dist_matrix.shape)\n",
    "#     hrs = []\n",
    "#     for i in range(dist_matrix.shape[0]):\n",
    "#         hr = find_hitrate(dist_matrix, i)\n",
    "#         hrs.append(hr)\n",
    "#     plt.plot(hrs)\n",
    "#     plt.show()\n",
    "#     print(hrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-motorcycle",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-robertson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-entry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-scanning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
